---
layout: default

---

## Motivation and Objectives

Deep neural networks (DNNs) are increasingly being used to model or approximate all com- ponents of traditional feedback control loops, including the plant, sensors, actuators, controllers, and in the case of so-called “end-to-end” architectures, the entire feedback loop itself! The excite- ment surrounding these developments has been palpable, expanding the scope of control theoretic techniques to a much wider range of systems and scenarios, including perception-based control, agile robotics, and autonomous driving and racing. However, until recently, what has been lack- ing has been a principled theoretical foundation that also allows for strong guarantees of stability, robustness, and safety to be provided when such deep learning-enabled components are intro- duced into the feedback loop. Further, existing results in this area are relatively inaccessible to a typical first or second year graduate student in control theory, as they require both sophisticated mathematical tools not typically included in a control theorist’s training (e.g., high-dimensional statistics and learning theory), as well as a breadth of multi-disciplinary knowledge from not only control theory, but also machine learning, optimization, and computer vision.

The objective of this workshop is to begin fostering a new interdisciplinary community and dialogue across the aforementioned disciplines of control theory, machine learning (ML), opti- mization, and computer vision, with the ultimate goal of making the important new results on the safety of deep learning enabled control systems more broadly accessible. To do so, we will invite six distinguished speakers according to the following breakdown: two from the control theory community, two from the ML/computer vision community, and two from the robotics community. Speakers will further be drawn from both academic and industry research labs. Talks will emphasize the interplay between learning and control and their effects on safety, robust- ness, and/or stability in the context of imitation learning, generative modeling, and computer vision/perception-based control, with applications to robotics and autonomous vehicles. The im- portance of verifiable and actionable conditions/algorithms in each of these applications, as well as potential implications/benefits to the public, will be emphasized.

