---
layout: default
title: main
---
#### Organizers 
Nikolai Matni (Penn), Christine Allen-Blanchette (Princeton), George Pappas (Penn)
*Contact:* nmatni@seas.upenn.edu

#### Relevant Links
- [IEEE CDC 2021 Workshops](https://2021.ieeecdc.org/workshops/)
- [IEEE CDC 2021 Registration](https://2021.ieeecdc.org/registration/)

## Motivation and Objectives

Deep neural networks (DNNs) are increasingly being used to model or approximate all components of traditional feedback control loops, including the plant, sensors, actuators, controllers, and in the case of “end-to-end” architectures, the entire feedback loop itself! The excitement surrounding these developments has been palpable, expanding the scope of control theoretic techniques to a much wider range of systems and scenarios, including perception-based control, agile robotics, and autonomous driving and racing. However, until recently, what has been lacking has been a principled theoretical foundation that also allows for strong guarantees of stability, robustness, and safety to be provided when such deep learning-enabled components are introduced into the feedback loop. Further, existing results in this area are relatively inaccessible to a typical first or second year graduate student in control theory, as they require both sophisticated mathematical tools not typically included in a control theorist’s training (e.g., high-dimensional statistics and learning theory), as well as a breadth of multi-disciplinary knowledge from not only control theory, but also machine learning, optimization, and computer vision.

The objective of this workshop is to begin fostering a new interdisciplinary community and dialogue across the aforementioned disciplines of control theory, machine learning (ML), optimization, and computer vision, with the ultimate goal of making the important new results on the safety of deep learning enabled control systems more broadly accessible. To do so, we have invited six distinguished speakers according to the following breakdown: two from the control theory community, two from the ML/computer vision community, and two from the robotics community. Speakers are further drawn from both academic and industry research labs. Talks will emphasize the interplay between learning and control and their effects on safety, robustness, and/or stability in the context of imitation learning, generative modeling, and computer vision/perception-based control, with applications to robotics and autonomous vehicles. The im- portance of verifiable and actionable conditions/algorithms in each of these applications, as well as potential implications/benefits to the public, will be emphasized.

## Prospective Audience

The workshop aims to initiate new lines of research that seek to integrate concepts from ML, computer vision, and control in novel ways so as to ensure that deep learning enabled control systems enjoy the same safety, stability, and robustness guarantees that have been the hallmarks of our community.  As such, the workshop is aimed a broad audience, but graduate students, postdocs, and junior professors are especially encouraged to participate in order to get initiated to this timely and exciting research area.  All talks will be broadly accessible to anyone with a basic familiarity with control theory, optimization, and machine/deep learning.

